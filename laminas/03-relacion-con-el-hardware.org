#+SETUPFILE: ../setup_laminas.org
#+TITLE: Relación con el hardware: Estructuras y funciones básicas
#+DATE:

* Fronteras del CPU
** ¿Qué es un /sistema von Neumann/?
- Computadora /de programa almacenado/
  - En la /memoria principal/
  - /Mismo almacenamiento/ para el programa siendo ejecutado que para
    sus datos
- Todas las computadoras que empleamos hoy en día son, para fines
  prácticos, sistemas von Neumann[fn:: Aunque podrían caracterizarse
  como /Harvard modificadas/ partiendo desde un formalismo
  excesivo...]

** Implicaciones de /von Neumann/
- La arquitectura /no considera/ la existencia de almacenamiento /persistente/
  - Dentro del procesador hay algunas (¡pocas!) localidaes para
    almacenar datos /muy limitados/, para /trabajar directamente con
    ellos/ \rarrow /Registros/
  - La computadora cuenta únicamente con la /memoria de trabajo/
    \rarrow RAM, /almacenamiento primario/
  - El almacenamiento a largo plazo debe hacerse empleando
    controladores / mecanismos alternos, en medios específicos \rarrow
    /almacenamiento secundario/

** Los registros
#+BEGIN_CENTER
¿Qué son los registros?
#+END_CENTER
- Memoria super-rápida (hoy en día, sub-nanosegundo), ubicada /dentro/
  del procesador
- Manejada /por referencia directa/, no por dirección
- Además de los datos del proceso guardan su /estado/
- ¿Qué significa /gestionados por el compilador/?

** Procesadores basados en /acumuladores/
- Primeros procesadores: Uno o pocos /acumuladores/. Por ejemplo:
  - MOS 6502:
    - 1 acumulador (A) de 8 bits
    - 2 registros índice de 8 bits (X y Y)
    - 1 registro de estado del procesador (P), un apuntador al stack
      de 8 bits (S), un apuntador a instrucciones (PC) de 8 bits
  - Zilog Z80 e Intel 8086:
    - 14 registros (3 de 8 bits, el resto de 16)
    - Pero sólo uno era un acumulador de propósito general

** Ejemplo de acumuladores: Intel 8086/8088
#+latex: \begin{columns}\begin{column}{0.5\textwidth}
#+attr_latex: :width \columnwidth
#+caption: Imagen de Wikipedia
[[../img/registros_8086.png]]
#+latex: \end{column}\begin{column}{0.5\textwidth}
Registros /bandera/ (vector de booleanos): Overflow, Dirección,
Interrupción, Trampa/depuración, Signo, Cero, Acarreo auxiliar,
Paridad, Acarreo
#+latex: \end{column}\end{columns}

** Registros de /propósito general/: Legado de RISC
- Procesadores RISC: A partir de los 1980
- Planteamiento base de instrucciones /sencillas y regulares/
  - Fáciles de codificar en un procesador pequeño (en número de
    transistores)
  - La arquitectura RISC más conocida hoy: ARM
- Típicamente $\ge 32$ registros /largos/ (32, 64bits) de propósito
  general
  - Mas algunos de propósito específico

** Tipos de almacenamiento
#+BEGIN_CENTER
¿Cómo representar y guardar /adecuadamente/ los datos e instrucciones?
#+END_CENTER
- La memoria rápida es muy cara
  - Pero aún así, mucho más lenta que el procesador: /Cuello de
    botella de von Neumann/ ([[https://dl.acm.org/citation.cfm?doid=359576.359579][Backus, 1977]])
- La memoria barata es muy lenta (/hasta 1000 veces/ más lenta que el procesador)
- El almacenamiento /a largo plazo/ es mucho más barato, pero
  muchísimo más lento
  - Los discos llegan a ser /miles a millones/ de veces más lentos que
    la memoria
- El avance en hardware /juega en contra/ de reducir la diferencia

** La memoria
- El procesador puede referirse directamente a los datos ubicados en
  la /memoria principal/ (/almacenamiento primario/)
  - Indicando su dirección (varias notaciones/mecanismos posibles)
  - Algunos procesadores permiten /realizar operaciones/ directamente
    sobre la memoria
    - Mayormente los basados en acumulador
- Memoria /caché/
  - Acelera operaciones aprovechando la /localidad de referencia/
  - Transparente a la programación (gestionada por el controlador)
  - Varios niveles de caché

** Jerarquía de almacenamiento
#+attr_latex: :height 0.7\textheight
#+caption: Diferentes niveles de almacenamiento: Diferencias en costo, velocidad y capacidad
[[../img/dot/jerarquia_memoria.png]]
** ¿Tiempo de acceso? ¿Tasa de transferencia?
#+BEGIN_CENTER
Manejaremos muchas mediciones de velocidad. Debemos siempre tener en cuenta:
#+END_CENTER
- Tiempo de acceso :: ¿Cuánto tiempo toma /iniciar/ una
     transferencia? (medido en s, ms, ns). También llamado /latencia/.
- Tasa de transferencia :: Una vez iniciada, ¿a qué velocidad
     /sostenida/ podemos mantenerla? (medido en b/s, Kb/s, Mb/s)
#+BEGIN_CENTER
En el /mejor caso/, la transferencia de $x$ bits nos tomará $t_a +
xt_t$
#+END_CENTER
** Jerarquía de almacenamiento
#+BEGIN_CENTER
#+latex: {\scriptsize
#+caption: Velocidad y gestor de los principales niveles de memoria. (Silberschatz, Galvin, Gagne; p.28)
| Nivel           | 1                 | 2              | 3              | 4          |
|-----------------+-------------------+----------------+----------------+------------|
| *Nombre*        | Registros         | Cache          | Memoria princ. | Disco      |
| *Tamaño*        | <1KB              | <16MB          | <64GB          | >100GB     |
| *Tecnología*    | Multipuerto, CMOS | SRAM CMOS      | CMOS DRAM      | Magnética  |
| *Acceso (ns)*   | 0.25-0.5          | 0.5-25         | 80-250         | 5,000,000  |
| *Transf (MB/s)* | 20,000-100,000    | 5,000-10,000   | 1,000-5,000    | 20-150     |
| *Administra*    | Compilador        | Hardware       | Sist. Op.      | Sist. Op.  |
| *Respaldado en* | Cache             | Memoria princ. | Disco          | CD o cinta |
#+latex: }
#+END_CENTER
** Almacenamiento /primario/ y /secundario/
- El procesador /sólo puede manejar directamente/ a la memoria
  principal
  - Se le conoce también como /almacenamiento primario/
  - Sólo éste es parte de lo que la arquitectura von Neumann llama
    /computadora/
- Discos, cintas, almacenamiento /estado sólido/ son /almacenamiento
  secundario/
  - Todas las computadoras lo manejan a través de /controladores/

* Conectando hacia afuera
** Canales y puentes
- Los componentes /no directamente referenciables/ de un sistema se
  comunican a través de /canales/ (/buses/)
  - Líneas de comunicación entre el procesador y el /chipset/
- Acomodo /muy frecuente/ en sistemas x86 recientes[fn:: Después del
  2010, las funciones del /Northbridge/ han tendido a ser absorbidas
  por el CPU mismo]:
  - Puente norte (Northbridge) :: Conectado directamente al CPU,
       encargado de los buses de alta velocidad y los dispositivos
       fundamentales para el inicio del sistema — Memoria, video (AGP)
  - Puente sur (Southbridge) :: Controla el resto de los dispositivos
       del sistema; de él se desprenden varios buses (SCSI / SATA /
       IDE, PCI / PCIe, USB / Firewire, puertos /heredados/)

** Canales y puentes
#+attr_latex: :height \textheight, angle=90
#+caption: Diagrama de la comuniacación entre componentes de un sistema de cómputo basado en /puente norte/ y /puente sur/
[[../img/northbridge_southbridge.png]]

** ¿Por qué tantos canales?
- Frecuencia acorde a distintas categorías de dispositivos
  - Criterio económico: Más barato usar señalización más lenta
  - Distintos mecanismos de acceso
- Permitir transferencias paralelas, agregarlas conforme subimos la
  jerarquía
  - Jerarquizar la comunicación
- Pero... Cuando el sistema requiere transferir datos de o hacia
  dispositivos pasando por el mismo bus, frecuentemente ocurre
  *contención*
  - Algunos canales, como el USB, permiten /hasta 127/ dispositivos
    conectados /serialmente/

** Ejemplo: Chipset Intel 875 (2003)
#+attr_latex: :width \textwidth
#+caption: Diagrama de la comuniacación entre componentes de un sistema de cómputo basado en el chipset Intel 875 (Pentium 4, 2003)
[[../img/dot/chipset_857.png]]

** Otros arreglos
- El ejemplo presentado es para un sistema de escritorio típico
  - Y bastante viejo ya
- En entornos de alto rendimiento, puede haber múltiples canales entre
  los componentes
  - Para reducir el impacto de la contención
  - Particularmente en los componentes con mayor demanda de ancho de banda
- En entornos móviles / de bajo costo, se hacen /concesiones/
  permitiendo mayor contención
  - P.ej. estructurar la comunicación a todos los periféricos
    alrededor del bus USB
  - Frecuente en equipos ARM

** Ejemplo: Raspberry Pi
#+attr_latex: :width \textwidth
#+caption: Diagrama de bloques de la popular plataforma ARM /Raspberry Pi/ de primera generación (Imagen de Wikipedia)
[[../img/raspberry_block_diag.png]]

* Interrupciones y excepciones

** El procesador y los /eventos/ externos
- El procesador no tiene cómo reaccionar /internamente/ a eventos que
  ocurran en el sistema
- La ejecución es lineal: Avanza por la lista de instrucciones del
  programa
- Lo que permite el manejo de toda la E/S, interactividad,
  multiprogramación es el mecanismo de /interrupciones/ y
  /excepciones/.

** Interrupciones y excepciones

- Interrupción :: Todo evento recibido por el sistema, de origen
                  /externo/ al flujo de la ejecución
  - Actividad en la red
  - Teclado o mouse
  - Alarma del temporizador
  - Datos del disco listos

- Excepción :: Eventos inesperados originados por el flujo del
               proceso
  - División sobre cero
  - Instrucción ilegal
  - Acceso a memoria no direccionada
  - También conocidas como /trampas/ (/traps/)

** Manejo de interrupciones y excepciones
- Todo /evento/ es recibido por el sistema operativo (no por los
  procesos)
- Cuando ocurre cualquier /evento/, el hardware /lanza una
  interrupción/ que interrumpe el flujo de ejecución
- Rutina de /manejo de interrupciones/
  - Grabar estado del proceso desplazado y /cambiar contexto/
  - Atender la interrupción en /modo privilegiado/ (¡el menor tiempo
    posible!)
  - Una vez procesada, volver a invocar al /planificador/

** ¿Cuándo una interrupción es /no enmascarable/?
- Depende de la arquitectura y los objetivos del sistema
- Algunos ejemplos:
  - Error de paridad en la memoria (IBM PC)
  - Llamadas a hardware incompatible (primeros /clones/ de IBM;
    llamada atrapada y procesada por el manejador de interrupciones en
    el BIOS)
  - Diversas combinaciones de teclas para invocar a un reinicio (o
    lanzar un depurador)
  - Consolas de 8 bits (Nintendo NES): Bloquear modificaciones al
    buffer de pantalla durante el refresco vertical

** Llamadas al sistema
- De cierto modo análogas/complementarias a las interrupciones
- Mecanismo para que un proceso /solicite un servicio/ al sistema
  operativo
- Cada sistema operativo /expone/ un diferente juego de llamadas al
  sistema a través de su API
- Es en buena medida lo que determina la /compatibilidad de código/
  entre sistemas operativos
  - Contraposición: Compatibilidad binaria
  - APIs implementados por diversos sistemas: POSIX, Win32

** Flujo de control en una llamada al sistema
#+attr_latex: :width \textwidth
#+caption: Transición del flujo entre espacio usuario y espacio núcleo en una llamada al sistema
[[../img/dot/llamada_al_sistema.png]]
** Tipos de llamadas al sistema (1)
#+BEGIN_CENTER
Lista incompleta, meramente ejemplificando
#+END_CENTER
- Control de procesos :: Crear o finalizar un proceso, obtener
     atributos del proceso, esperar cierto tiempo, asignar o liberar
     memoria, etc.

- Manipulación de archivos :: Crear, borrar o renombrar un archivo;
     abrir o cerrar un archivo existente; modificar sus /metadatos/;
     leer o escribir de un /descriptor de archivo/ abierto, etc.

** Tipos de llamadas al sistema (2)
#+BEGIN_CENTER
Lista incompleta, meramente ejemplificando
#+END_CENTER
- Manipulación de dispositivos :: Solicitar o liberar un dispositivo;
     leer, escribir o reposicionarlo, y otras varias. Muchas de estas
     llamadas son análogas a las de manipulación de archivos, y varios
     sistemas operativos las ofrecen como una sola.
- Mantenimiento de la información :: Obtener o modificar la hora del
     sistema; obtener detalles acerca de procesos o archivos, etc.

** Tipos de llamadas al sistema (3)
#+BEGIN_CENTER
Lista incompleta, meramente ejemplificando
#+END_CENTER
- Comunicaciones :: Establecer una comunicación con determinado
                    proceso (local o remoto), aceptar una solicitud de
                    comunicación de otro proceso, intercambiar
                    información sobre un canal establecido

- Protección :: Consultar o modificar la información relativa al
                acceso de objetos en el disco, otros procesos, o la
                misma sesión de usuario

** Depuración por /trazas/
- La mayor parte de los sistemas operativos ofrecen programas que
  ayudan a /depurar la ejecución/ de otros programas
- Pueden /envolver/ al API del sistema, y permitir seguir la /traza/
  (/trace/) de la ejecución de un proceso
- Por ejemplo:
  - =strace= en Linux
  - =truss= en Unixes históricos
  - =ktrace=, =kdump= en *BSD
  - =dtrace= en Solaris $\ge 10$ (2005)
- Permite entender /buena parte/ de lo que realiza un proceso —
  Prácticamente, toda su interacción con el sistema
  - A veces, demasiada información

** Ejemplo: =$ strace pwd=
#+begin_src C
execve("/bin/pwd", ["pwd"], [/* 43 vars */]) = 0
brk(0)                                  = 0x8414000
access("/etc/ld.so.nohwcap", F_OK)      = -1 ENOENT (No such file or directory)
mmap2(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb773d000
             (...)
getcwd("/home/gwolf/vcs/sistemas_operativos", 4096) = 36
fstat64(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 1), ...}) = 0
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb773c000
write(1, "/home/gwolf/vcs/sistemas_operati"..., 36/home/gwolf/vcs/sistemas_operativos
) = 36
close(1)                                = 0
munmap(0xb773c000, 4096)                = 0
close(2)                                = 0
exit_group(0)                           = ?
#+end_src

** Acceso directo a memoria (DMA)
#+BEGIN_CENTER
Problema: En la sección de un proceso en que está /limitado por
entrada-salida/, la transferencia de información se vuelve cuello de
botella
#+END_CENTER
- Modo /entrada/salida programada/
- Gran cantidad y frecuencia de interrupciones
- Imposible realizar trabajo real
#+BEGIN_CENTER
Respuesta: /Acceso Directo a Memoria/
#+END_CENTER

** Acceso directo a memoria (DMA)
- Orientado a dispositivos de gran ancho de banda
  - Unidades de disco
  - Multimedia
  - Red
  - Memoria y caché
- Transferencia en bloques, empleando un /controlador/
  - Dirección física base de memoria
  - Cantidad de datos a transferir
  - /Puerto/ del dispositivo
  - Dirección de la transferencia (/desde/ o /hacia/ memoria)
- Limitante: Contención en el bus de memoria

** Coherencia de caché
#+BEGIN_CENTER
¿Qué problema puede causar una transferencia /no iniciada por el
procesador/? (O por /otros procesadores/)
#+END_CENTER
\pause
- Incongruencia entre la memoria real y /páginas/ de caché existentes
  - Caché coherente :: Mecanismos /en hardware/ que notifican a los
       controladores de caché que las páginas están /sucias/
  - No coherente :: El sistema operativo debe realizar esta operación
- Sistemas híbridos en lo relativo a la coherencia
  - Caché de nivel superior (en el procesador) no coherente, cachés
    inferiores coherentes

* Organización del sistema operativo

** Separación /espacio núcleo/ y /espacio usuario/
- Evolución de los tipos de /modo protegido/ de los sistemas monitores
  - ¿Dos modos? ¿Más modos?
- Código con diferentes roles
  - Lo que hace el sistema operativo vs. las aplicaciones del usuario
- ¿Cómo se /salta/ entre un modo y otro?

** Organización del sistema operativo
#+BEGIN_CENTER
¿Hasta dónde llega el sistema operativo?

¿Hasta dónde llega el código que corre en modo protegido/espacio
núcleo?
#+END_CENTER
- Monolítico :: Todas las operaciones privilegiadas en el mismo
                /super-proceso/.
- Microkernel :: Un núcleo con el mínimo posible de funcionalidad,
                 descargando en /procesos especiales/ ciertas tareas
- Híbridos :: Sistemas que entran mayormente en una categoría, pero
              tienen alguna excepción
** Monolíticos
- La mayor parte de los sistemas históricamente

- Más fáciles de diseñar
  - (¡No es lo mismo que /diseño más simple/!)

- Estructuras compartidas directamente entre subsistemas

- Más rápidos (menos /cambios de contexto/)

- Difícil transición a un entorno multiprocesador

** Monolíticos: Esquematizando
#+attr_latex: :height 0.7\textheight
[[../img/dot/diseno_monolitico.png]]

** Microkernel
- Se delegan a /espacio usuario/ todos los procesos que sea posible
  - p.ej. sistemas de archivos, planificación de procesos,
    administración de memoria, dispositivos, modelo de seguridad…

- Código resultante /más limpio/
  - Interfaces claras, separación de responsabilidades
  - Seguridad: Verificabilidad, /auto-reparación/
  - Más fácil pasar a multiprocesador

- Más lentos
  - Típicamente basados en /paso de mensajes/
  - Requieren más cambios de contexto

- Más difíciles de implementar correctamente

** Microkernel: Esquematizando
#+attr_latex: :height 0.7\textheight
[[../img/dot/diseno_microkernel.png]]

** Diseño híbrido
- Hay componentes que pueden migrarse limpiamente de un esquema
  monolítico a uno microkernel
- Pero hay componentes para los cuales dicha tarea resulta muy cara
  - Incluso en sistemas diseñados originalmente como microkernel
- Hoy en día encontraremos concepciones híbridas, con características
  de ambos

** Diseño híbrido: Esquematizando
#+attr_latex: :height 0.7\textheight
   [[../img/dot/diseno_hibrido.png]]


* Multiprocesamiento
** Multiprocesamiento y multiprogramación
#+BEGIN_CENTER
Conceptos relacionados, empleados coloquialmente de forma
intercambiable, pero muy distintos:
#+END_CENTER
- Multiprogramación :: /Ilusión/ de estar ejecutando varios procesos
     al mismo tiempo, por medio de la /alternación rápidamente/ entre
     ellos
     - En un principio, no tan rápidamente; hoy en día, cientos a
       miles de veces por segundo
- Multiprocesamiento :: Entorno donde hay más de un procesador central
     (CPU).
     - Por muchos años, reservado a usos muy especializados
     - Hoy en día, la norma.

** Multiprogramación, multiprocesamiento, híbrido...
#+attr_latex: :height 0.5\textheight
#+caption: Esquema de la ejecución de tres procesos en un sistema secuencial, multiprogramado, multiprocesado, e híbrido
[[../img/ditaa/multiproceso_y_multiprogramacion.png]]

** Formalizando un poco
- /Sólamente/ un sistema multiprocesador tiene la capacidad /real/ de
  atender /simultáneamente/ a diversos procesos
- Hoy en día es muy raro aplicar /de forma exclusiva/ a cualquiera de
  estas modalidades
  - Multiprogramado puro: Sigue siendo común en equipos
    no-multiprocesados
  - ...Pero cada vez son menos

** Acostumbrémonos, porque...
#+BEGIN_CENTER
El tema que más recurrentemente abordaremos en el curso es /la
complejidad/ que proviene tanto de la multiprogramación como de la
multitarea

Particularmente la abordaremos en las dos siguientes unidades:
/Administración de procesos/ y /Planificación de procesos/.
#+END_CENTER

** La irrupción del multiprocesamiento
- Existe desde los 1960
- Entornos de alto rendimiento, /muy especializados/
  - Requieren una programación hecha /con cuidado especial/
- Hace apenas 10-15 años, muchos sistemas operativos no detectaban
  siquiera más de un procesador
  - Incluso de rango servidor
  - Era muy raro encontrarlos en hardware de uso frecuente
- Pero hacia el 2005... Nos alcanzó Gordon E. Moore

** ¿Gordon E. Moore?
- Ingeniero electrónico, fundador de /Fairchild Semiconductor/
- Publicó en 1965 /[[http://cs.utexas.edu/~fussell/courses/cs352h/papers/moore.pdf][Cramming more components onto integrated circuits]]/
  (/Apretujando más componentes en circuitos integrados/)
- Observando el desarrollo desde 1959, predice que cada año se
  duplicará la cantidad de transistores en los circuitos integrados,
  al menos por los próximos 10 años

** La Ley de Moore, 1965
#+attr_latex: :height 0.7\textheight
#+caption: La /Ley de Moore/, en su artículo publicado en 1965, prediciendo la miniaturización por diez años
[[../img/moore_orig.png]]

** La Ley de Moore, hoy
#+latex: \begin{columns}\begin{column}{0.7\textwidth}
#+attr_latex: :height 0.9\textheight
[[../img/gnuplot/ley_de_moore.png]]
#+latex: \end{column}\begin{column}{0.3\textwidth}
#+BEGIN_CENTER
Y a cinco decadas, la Ley de Moore se sigue cumpliendo...
#+END_CENTER
#+latex: \end{column}\end{columns}

** ¿Moore y el multiprocesamiento?
#+BEGIN_CENTER
¿Qué tiene que ver la Ley de Moore y el multiprocesamiento?
#+END_CENTER
- Hasta $\approx 2005$, la velocidad de los CPUs crecía constantemente
  - En el ámbito comercial, excediendo los 3 GHz
  - Llevando a problemas serios de calentamiento
- El diferencial de velocidad con el acceso a memoria crece cada vez
  más
- Hace falta un cambio de estrategia...

** Chips multiprocesador
- Los principales fabricantes de CPUs comenzaron a diseñar chips
  conteniendo más de un /núcleo/ — Esto es, más de un CPU independiente
  - (Y algunas facilidades adicionales — Por ejemplo, mucho mayor
    caché /dentro del mismo/ chip)
- El reloj de los procesadores no sólo no ha crecido, sino que en
  general /se redujo/ a cerca de 1GHz
  - Apenas 15 años más tarde estamos volviendo a esas velocidades (y
    con menor /protagonismo/)
  - Obviamente, el rendimiento y la densificación siguen avanzando
- Pero ahora la ganancia de velocidad ya no llega en automático con el
  nuevo hardware
  - El sistema operativo tiene que saber /aprovechar/ al
    multiprocesamiento

** ¿Cómo multiprocesamos?
#+BEGIN_CENTER
Hoy en día, cuando hablamos de multiprocesamiento, /casi/ siempre
hablamos de multiprocesamiento simétrico
\vfill

...Pero no es el único tipo de multiprocesamiento que hay
#+END_CENTER

** Multiprocesamiento simétrico (SMP)
- Todos los procesadores /son iguales/
- Pueden realizar las mismas operaciones en el mismo tiempo
- Un proceso podría /migrarse/ de un procesador a otro de forma
  transparente
  - Únicamente manteniendo información básica
- Tienen /acceso a la misma memoria/
  - Aunque cada uno puede tener su propio caché \rarrow
    *¡Necesidad de coherencia!*

** Multiprocesamiento asimétrico
#+BEGIN_CENTER
Puede haber varios puntos de asimetría:
#+END_CENTER
- Distinta /arquitectrura/ \rarrow Típicamente algunos se dedicarán a una
  tarea específica
- Coprocesadores, o procesadores coadyuvantes
  - Caso de las tarjetas gráficas (GPUs)
  - Podrían verse /casi/ como una red alta velocidad de computadoras
    /independientes/
- Memoria y responsabilidades muy distintas a las del sistema central

** Acceso no-uniforme a memoria (NUMA)
#+BEGIN_CENTER
(/Non-Uniform Memory Access/)
#+END_CENTER
- Procesadores de la misma arquitectura/tipo
  - Podrían formar parte de un sistema SMP
- Pero con /afinidad/ a bancos específicos de memoria
  - Memoria /cercana/ o /lejana/
  - Al /planificar/ los procesos, se destinan los procesadores cercanos
  - Hay un /canal compartido/ de memoria
- Típicamente computadoras grandes con /nodos/ o /blades/
- Pueden ubicarse como en un punto medio entre SMP y el /cómputo
  distribuído/
  - Cómputo distribuído fuertemente acoplado

** Más allá: Cómputo distribuído
- Distribuir un proceso de cómputo para ser realizado /entre
  computadoras independientes/
  - Más formalmente: Entre procesadores /que no comparten memoria/
    (almacenamiento primario)
- Dos modalidades principales (mas un /adosado/):
  - Cúmulos (/clusters/)
  - Mallas (/grids/)
  - Cómputo /en la nube/

** Cúmulos (clusters)
- Computadoras conectadas por una red local de alta velocidad
- Cada una corre su propia instancia de sistema operativo y programas
- Principales orientaciones:
  - Alto rendimiento :: Cómputo matemático, cálculos...
  - Alta disponibilidad :: Prestación de servicios críticos
  - Balanceo de cargas :: Atención a solicitudes complejas, que pueden
       saturar a servidores individuales
- Típicamente son equipos homogéneos y dedicados
- Muy comunes en universidades; bajo costo, altas prestaciones

** Mallas (grids)
- Computadoras distribuidas geográficamente
- Conectadas sobre Internet (o redes de área amplia)
- Pueden ser heterogéneas (en capacidades y en arquitectura)
- Presentan /elasticidad/ para permitir conexiones/desconexiones de
  nodos en el tiempo de vida de un cálculo
\pause
#+BEGIN_CENTER
¿Quién quiere presentar el ejemplo de alguna malla?
#+END_CENTER

** Cómputo en la nube
- Caso específico y /de moda/
- Partición de recursos (/cliente-servidor/)
- Orientado a la /tercerización/ de servicios específicos
- La /implementación/ de un servicio deja de ser relevante \rarrow
  Procesos /opacos/
- Conceptos relacionados:
  - /Servicios Web/
  - Plataforma como servicio (/PaaS/)
  - Software como servicio (/SaaS/)
  - Infraestructura como servicio (/IaaS/)

** Límites del paralelismo
- [[http://turing.eas.asu.edu/cse520fa08/Alaw.pdf][Gene Amdahl (1967)]] observó que la ganancia derivada de paralelizar
  el código llega a un límite natural: El tiempo requerido por la
  /porción secuencial/ del código
- La /porción paralelizable/ puede repartirse entre varios
  procesadores, pero siemprehay una importante proporción no
  paralelizable
  - Inicialización
  - Puntos de control/acumulación de datos
  - Interacción con el usuario
  - etc.

** Ley de Amdahl
- $T(1)$ :: Tiempo de ejecución del programa con un sólo procesador
- $T(P)$ :: Tiempo de ejecución con $P$ procesadores
- $t_s$ :: Tiempo requerido por la porción secuencial
- $t_p(P)$ :: Tiempo requerido para la porción paralela entre $P$
  procesadores
#+BEGIN_CENTER
$g=\frac{T(1)}{T(P)}=\frac{t_s+t_p(1)}{t_s+\frac{t_p(1)}{P}}$
#+END_CENTER

** Ilustrando la ley de Amdahl (1)
#+begin_latex
\begin{columns}
\begin{column}{0.3\textwidth}
  \centering
  \includegraphics[height=0.33\textheight]{../img/dot/amdahl_1.png} \\
  Procesadores: 1, $t=500$
\end{column}
\begin{column}{0.3\textwidth}
  \centering
  \includegraphics[height=0.33\textheight]{../img/dot/amdahl_2.png} \\
  Procesadores: 2, $t=400$, ganancia: 1.25x
\end{column}
\begin{column}{0.3\textwidth}
  \centering
  \includegraphics[height=0.33\textheight]{../img/dot/amdahl_4.png} \\
  Procesadores: 4, $t=350$, ganancia: 1.4x
\end{column}
\end{columns}
#+end_latex
#+BEGIN_CENTER
Ley de Amdahl: ejecución de un programa con 500 unidades de tiempo total de trabajo con uno, dos y cuatro procesadores.
#+END_CENTER

** Ilustrando la ley de Amdahl (2)
#+attr_latex: :width 0.6\textwidth
#+label: HW_amdahl_porcentajes
#+caption: Ganancia máxima al paralelizar un programa, según la Ley de Amdahl
[[../img/gnuplot/amdahl.png]]

** Desmenuzando a Amdahl
- El paralelismo puede aumentar fuertemente nuestro rendimiento
  - ... ¿O no?
- Incluso con un 95% de ejecución paralela, se llega a un techo de
  ganancia al llegar a los 20 CPUs
  - Cada procesador tiene un costo económico no trivial
  - ¿Vale realmente la pena ir migrando hacia un paralelismo cada vez
     mayor?

** Observación de Gustafson
- Por muchos años, la ley de Amdahl disminuyó el interés en el cómputo
  paralelo
- En 1988, John Gustafson obtuvo ganancias superiores a 1020x en una
  supercomputadora de 1024 procesadores
- [[http://www.johngustafson.net/pubs/pub13/amdahl.htm][Publicó una observación]] que hizo re-evaluar este conocimiento
- La modificación no (sólo) será al tiempo de cómputo, /sino que al
  problema mismo/
- Un artículo de apenas una cuartilla y lenguaje muy sencillo rompió
  el /bloqueo mental/ contra el paralelismo

** Observación de Gustafson
  \small

(...)Asumen implícitamente que el tiempo que se ejecuta en paralelo es
independiente del número de procesadores, *lo cual virtualmente nunca
ocurre de este modo*. Uno no toma un problema de tamaño fijo para
ejecutarlo en varios procesadores como no sea para hacer un ejercicio
académico; en la práctica, *el tamaño del problema crece con el número
de procesadores*. \vfill

Al obtener procesadores más poderosos, el problema generalmente se
expande para aprovechar las facilidades disponibles. Los usuarios
tienen control sobre cosas como la resolución de la malla, el número
de pasos, la complejidad de los operadores y otros parámetros que
usualmente se ajustan para permitir que el programa se ejecute en el
tiempo deseado. \vfill

Por tanto, podría ser más realista decir que el *tiempo de ejecución*,
no el *tamaño del problema*, es constante.

