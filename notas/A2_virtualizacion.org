#+SETUPFILE: ../setup_notas.org
#+TITLE: Virtualización

* Introducción
# <<VIRT>>

La /virtualización/ no es un concepto nuevo. Sin embargo, tras largos
años de estar relegado a un segundo plano, en la actualidad se torna
fundamental en referencia a los sistemas operativos, particularmente en
papel de servidores. Este tema se abordará de momento desde un
punto de vista más bien descriptivo, y posteriormente se profundizará en
algunos de sus asepectos.

En primer término, es importante aclarar que el concepto de /virtualización/ 
no se refiere a una única tecnología o metodología, es un término que
agrupa a muy distintas tecnologías que hay –de
diversas formas– desde hace décadas. Cada una de ellas tiene su lugar,
con diferentes usos y propósitos, algunos de los cuales se usan de forma
transparente para el usuario promedio.

Del mismo modo, aunque se abordarán diversas tecnologías que pueden
clasificarse como virtualización, la línea divisoria entre cada una de ellas no
siempre es clara. Una implementación específica puede caer en más
de una categoría, o puede ir migrando naturalmente de un tipo hacia
otro.

En escala general, /virtualizar/ consiste en proveer algo que no está ahí,
aunque parezca estarlo. Más específicamente, presentar a un sistema elementos
que se comporten de la misma forma que un componente físico (hardware), sin que 
exista en realidad —un acto de ilusionismo o de magia, en el cual se busca
presentar el elemento de forma tan convincente que la ilusión se mantenga tanto
como sea posible.[fn:: Una aproximación inicial a este concepto puede ser
un archivo con la imagen de un disco en formato *iso*: mediante determinados mecanismos, es posible
"engañar" a un sistema operativo de forma que "piense" que al acceder al archivo *iso*
está efectivamente leyendo un *cd* o *dvd* de una unidad que no existe físicamente.]

La naturaleza de dichos elementos, y el cómo se implementan, dependen del
tipo de virtualización.

Para casi todos los casos que se presentan, se emplearán los siguientes términos:

- Anfitrión :: El hardware o sistema /real/, que ofrece el mecanismo de
               virtualización. En inglés se le denomina /host/.

- Huésped :: El sistema o las aplicaciones que se ejecutan en el entorno
	     virtualizado. En inglés se les denomina /guest/.

* Emulación

La técnica de virtualización más sencilla, y que hace más tiempo
tienen las computadoras personales, es la emulación. Emular
consiste en implementar /en software/ algo que se presente como el
hardware de un sistema de cómputo completo, típicamente de una arquitectura hardware
distinta a la del anfitrión (la arquitectura /nativa/).[fn:: A lo largo de esta discusión, se hará
referencia a la /arquitectura hardware/ como al juego de
instrucciones que puede ejecutar /nativamente/ un procesador. Por
ejemplo, un procesador x86 moderno puede ejecutar nativamente código
i386 y x86\_64, pero no *arm*.] El emulador puede ser visto (de una forma
tremendamente simplificada) como una lista de equivalencias, de cada
una de las instrucciones en la arquitectura /huésped/ a la
arquitectura del sistema /anfitrión/.

Vale la pena recalcar que una emulación no se limita con traducir del
lenguaje y la estructura de un procesador a otro —para que una
computadora pueda ser utilizada, requiere de una serie de chips de
apoyo, desde los controladores de cada uno de los /buses/ hasta los
periféricos básicos (teclado, video). Casi todas las emulaciones
incluirán un paso más allá: los periféricos mismos (discos, interfaces
de red, puertos). Todo esto tiene que ser implementado por el
emulador.

Resulta obvio que emular un sistema completo es /altamente/
ineficiente. Los sistemas huéspedes resultantes típicamente tendrán un
rendimiento cientos o miles de veces menor al del anfitrión.

Ahora bien, ¿qué pasa cuando hay dos arquitecturas de cómputo que
emplean el mismo procesador? Este caso fue relativamente común en la
década de los ochenta y noventa; si bien en general las computadoras
de 8 bits no tenían el poder de cómputo necesario para implementar la
emulación de arquitecturas similares, al aparecer tres líneas de
computadoras basadas en el *cpu* Motorola 68000 (Apple Macintosh,
Atari *st* y Commodore Amiga), diferenciadas principalmente por sus
/chipsets/, aparecieron emuladores que permitían ejecutar programas de
una línea en la otra, prácticamente a la misma velocidad que en el
sistema nativo.

Hoy en día, la emulación se emplea para hacer /desarrollos cruzados/,
más que para emplear software /ya escrito y compilado/.  La mayor
parte de la emulación tradicional se emplea para el /desarrollo de
software/. Hoy en día, la mayor parte de las computadoras vendidas son
sistemas /embebidos/[fn:: Computadoras pequeñas, limitadas en
recursos, y típicamente carentes de una interfaz usuario — desde
puntos de acceso y ruteadores hasta los controladores de cámaras,
equipos de sonido, automóviles, y un larguísimo etcétera.] o
dispositivos móviles, que hacen imposible (o, por lo menos, muy
difícil) desarrollar software directamente en ellos. Los programadores
desarrollan en equipos de escritorio, ejecutan entornos de prueba en
emuladores del equipo destino. A pesar del costo computacional de
realizar la emulación, la diferencia de velocidad entre los equipo de
escritorio de gama alta y los embebidos permiten que frecuentemente la
velocidad del emulador sea muy similar –incluso superior– a la del
hardware emulado.

** Emulando arquitecturas inexistentes
# <<VIRT_arq_inexistentes>>

Pero la emulación no se limita a hardware existente, y no sólo se
emplea por la comodidad de no depender de la velocidad de equipos
específicos. Es posible crear emuladores para arquitecturas que /nunca
han sido implementadas/ en hardware real.

Esta idea viene de los setenta, cuando comenzó la explosión de
arquitecturas. La Universidad de California en San Diego propuso una
arquitectura llamada /p-system/, o /sistema-p/, la cual definiría una
serie de instrucciones a las que hoy se clasificarían como /código intermedio/ o
/bytecode/, a ser ejecutado en una /máquina-p/, o /p-machine/. El
lenguaje base para este sistema fue el /Pascal/, mismo que fue
adoptado muy ampliamente de manera principal en entornos académicos a
lo largo de los setenta y ochenta por su limpieza y claridad
estructural. Todo programa compilado para ejecutarse en un /sistema-p/
ejecutaría sin modificaciones en cualquier arquitectura hardware que lo
implementara.

Los /sistemas-p/ gozaron de relativa popularidad hasta mediados de los
ochenta, logrando implementaciones para las arquitecturas de
microcomputadoras más populares —el *mos* 6502, el Zilog *z80* y el
Intel 80x86.

Hay una diferencia muy importante entre la emulación de una
arquitectura real y la de una inexistente: emular una
computadora entera requiere implementar no sólo las
instrucciones de su procesador, sino que /todos los chips de apoyo/,
¡incluso hay que convertir la entrada del teclado en las
interrupciones que generaría un controlador de teclado! Emular una
arquitectura hipotética permite manejar diversos componentes de forma
abstracta, y también definir estructuras de mucho más alto nivel que
las que se encuentran implementadas en hardware. Por ejemplo, si bien
resultaría impráctico crear como tipo de datos nativo para una
arquitectura en hardware una abstracción como las cadenas de
caracteres, estas sí existen como /ciudadanos de primera clase/ en
casi todas las arquitecturas meramente virtuales.

Esta idea ha sido ampliamente adoptada y forma parte de
la vida diaria. En la década de los noventa, /Sun Microsystems/
desarrolló e impulsó la arquitectura /Java/, actualizando la idea de
las /máquinas-p/ a los paradigmas de desarrollo que aparecieron a lo
largo de 20 años, y dado que el cómputo había dejado de ser un campo
especializado y escaso para masificarse, invirtiendo fuertemente en
publicidad para impulsar su adopción.

Uno de los slogans que mejor describen la intención de Sun fue *wora*:
/Write Once, Run Anywhere/ (escribe una vez, ejecuta donde sea). El
equivalente a una /máquina-p/ (rebautizada como *jvm*: /Máquina
Virtual Java/) se implementaría para las arquitecturas hardware más
limitadas y más poderosas. Sun creó también el lenguaje Java, diseñado
para aprovechar la arquitectura de la *jvm*, enfatizando en la
orientación a objetos e incorporando facilidades multi-hilos. Al día
de hoy hay distintas implementaciones de la *jvm*, de diferentes
empresas y grupos de desarrolladores y con diversos focos de
especialización, pero todas ellas deben poder ejecutar el /bytecode/
de Java.

A principios de los años 2000, y como resultado del litigio con Sun
que imposibilitó a Microsoft a desarrollar extensiones propietarias a
Java (esto es, desarrollar máquinas virtuales que se salieran del
estándar de la *jvm*), Microsoft desarrolló la arquitectura *.net*. Su
principal aporte en este campo es la separación definitiva entre
lenguaje de desarrollo y código intermedio producido: la máquina
virtual de *.net* está centrada en el *cli* (/Common Language
Infrastructure/, Infraestructura de Lenguajes Comunes), compuesta a su
vez por el *cil* (/Common Intermediate Language/, Lenguaje Intermedio
Común, que es la especificación del /bytecode/ o código intermedio) y
el *clr* (/Common Language Runtime/, Ejecutor del Lenguaje Común, que
es la implementación de la máquina virtual sobre la arquitectura
hardware nativa).

#+attr_latex: width=0.6\textwidth
#+attr_html: height="600"
#+label: VIRT_maquina_virtual_dotnet
#+caption: Arquitectura de la infraestructura de lenguajes comunes (*cli*) de *.net* (imagen de la Wikipedia: /Common Language Infrastructure/).
[[./img/maquina_virtual_dotnet.png]]

En los años noventa, una de las principales críticas a Java (la cual
podría ampliarse hacia cualquier otra plataforma comparable) era el
desperdicio de recursos de procesamiento al tener que traducir, una y
otra vez, el código intermedio para su ejecución en el
procesador. Hacia el 2010, el panorama había cambiado fuertemente. Hoy
en día las máquinas virtuales implementan varias técnicas para reducir
el tiempo que se desperdicia emulando:

- Traducción dinámica :: Compilación parcial del código a ejecutar a
     formatos nativos, de modo que sólo la primera vez que se ejecuta
     el código intermedio tiene que ser traducido.
- Traducción predictiva :: Anticipar cuáles serán las siguientes
     secciones de código que tendrán que ser ejecutadas para,
     paralelamente al avance del programa,  traducirlas a código
     nativo de forma preventiva.
- Compilación /justo a tiempo/ (*jit*) :: Almacenar copia del código
     ya traducido de un programa, de modo que no tenga que hacerse ni
     siquiera en cada ejecución, sino que sólo una vez en la vida de
     la máquina virtual.

Mediante estas estrategias, el rendimiento de las arquitecturas
emuladas es ya prácticamente idéntico al del código compilado
nativamente.

** De lo abstracto a lo concreto

Si bien las arquitecturas de máquinas virtuales planteadas en el
apartado anterior se plantearon directamente para no ser implementadas
en hardware, el éxito comercial de la plataforma llevó a crear una
línea de chips que ejecutara /nativamente/ código intermedio Java, con
lo cual podrían ahorrarse pasos y obtener mejor rendimiento de los
sistemas destino. Sun definió la arquitectura *majc* (/Microprocessor
Architecture for Java Computing/, arquitectura de microprocesadores
para el cómputo con Java) en la segunda mitad de los noventa, e
incluso produjo un chip de esta arquitectura, el *majc 5200*.

La arquitectura *majc* introdujo conceptos importantes que han sido
retomados para el diseño de procesadores posteriores, pero la
complejidad llevó a un rendimiento deficiente, y el chip resultó un
fracaso comercial.

Es importante mencionar otra aproximación. Transitando en el sentido
inverso al de Sun con *majc*, /Transmeta/, una empresa hasta entonces
desconocida, anunció en el 2000 el procesador /Crusoe/, orientado al
mercado de bajo consumo energético. Este procesador, en vez de
implementar una arquitectura ya existente para entrar a un mercado ya
muy competido y dinámico, centró su oferta en que Crusoe trabajaría
mano a mano con un módulo llamado *cms* (/Code Morphing Software/,
Software de Transformación de Código), siendo así el primer procesador
diseñado para /emular por hardware/ a otras arquitecturas. Crusoe fue
lanzado al mercado con el *cms* para la arquitectura x86 de Intel, y
efectivamente, la emulación era completamente transparente al
usuario.[fn:: Empleando Transmeta, se podían observar ciertos
comportamientos curiosos: por ejemplo, dado el amplio espacio de caché
que implementaba el *cms*, el código ejecutable se mantenía /ya
traducido/ listo para el procesador. Por tal motivo, la primera vez
que se ejecutaba una función era notablemente más lenta que en
ejecuciones posteriores. Sin embargo, si bien estas diferencias son
medibles y no deben escapar a la vista de quien está analizando a
conciencia estos procesadores, resultaban invisibles para el usuario
final.] El procesador mismo, además, no implementaba algunas
características que hoy se consideran fundamentales, como una
unidad de manejo de memoria, dado que eso podía ser implementado por
software en el *cms*. Separando de esta manera las características
complejas a una segunda capa, podían mantenerse más bajos tanto el
número de transistores (y, por tanto, el gasto energético) y los
costos de producción.

La segunda generación de chips Transmeta (/Efficeon/) estaba basada
en una arquitectura muy distinta, buscando un rendimiento mejorado.
Pero, gracias al *cms*, esto resulta imperceptible al usuario.

A pesar de estas ideas interesantes y novedosas, Transmeta no pudo
mantener el dinamismo necesario para despegar, y cesó sus operaciones
en 2009.

** ¿Emulación o simulación?

Una pregunta frecuente que se presenta al hablar de este tema es
acerca de la diferencia entre la /emulación/ y la /simulación/. Todos
los casos presentados anteriormente se tratan de /emulación/.

Emular significa /imitar las acciones de otro, procurando igualarlas e
incluso excederlas/ (Diccionario de la Real Academia Española, 23ª
edición). Esto significa que un emulador reproduce todos los procesos
internos que realizaría el sistema nativo, y busca cubrir todos los
comportamientos respectivos implementando los mismos mecanismos.

/Simular/, por otra parte, y según este mismo diccionario, significa
/representar algo, fingiendo o imitando lo que no es/. Un sistema
simulador simula o finge las áreas de determinado sistema que
interesan al usuario; puede emplear datos precargados para generar
ciertas respuestas, obviando los procesos que los generarían.

A diferencia de los ejemplos presentados a lo largo de esta sección,
que llevan a ejecutar software arbitrario para la plataforma destino
buscando idealmente que éstos no detecten siquiera una diferencia en
comportamiento, un simulador puede presentar mucho mayor detalle en
determinadas áreas, pero no realiza las funciones sustantivas del
sistema simulado. Por ejemplo, es muy común (incluso para el
entrenamiento de pilotos reales) el uso de simuladores de vuelo; estos
programas pueden representar una cabina equivalente a la de un avión
real, con todos sus monitores y controles, pero nadie esperaría que lo
trasladen de un lugar a otro. Muchos de los lectores habrán empleado
software de simulación de circuitos electrónicos, que permiten el
diseño y pruebas simples de circuitos, pero no esperarán que simular
en la computadora un núcleo de ferrita rodeado por una bobina resulte
en un receptor de radio.

* Virtualización asistida por hardware
# <<VIRT_asist_por_hw>>

Actualmente se usa la virtualización como una herramienta para la
consolidación de servicios, de gran ayuda para los administradores de
sistemas. Este uso se refiere principalmente a lo que se presentará en
este apartado, así como en las secciones \ref{VIRT_paravirt}
(/Paravirtualización/) y \ref{VIRT_contenedores} (/Contenedores/). Y
si bien este /zumbido/ de la virtualización se ha producido mayormente
a partir del 2006-2007, no se trata de tecnologías o ideas novedosas —
pueden encontrarse ejemplos desde finales de los sesenta. Hasta hace
algunos años, sin embargo, se mantenía dentro del ámbito de los
servidores en gran escala, fuera del alcance de la mayor parte de los
usuarios. Es necesario estudiar la génesis de esta herramienta, para
poder comprender mejor cómo opera y se implementa.

En 1964, *ibm* creó la primer /familia de computadoras/, la
serie 360. Presentaron la entonces novedosa idea de que una
organización podía adquirir un modelo sencillo y, si sus necesidades
se ajustaban al modelo de cómputo, podrían migrar fácilmente hacia
otros más poderosos, dado que tendrían /compatibilidad binaria/.

Uno de los modelos de esta familia fue la /S-360-67/, con la
característica distintiva de ser la única de la serie 360 en ofrecer
una unidad de manejo de memoria (*mmu*), con lo cual permitía la
reubicación de programas en memoria. Esto, sin embargo, creaba un
problema: el software desarrollado para los equipos más pequeños de la
familia estaba creado bajo un paradigma de usuario único, y si bien
podría ser ejecutado en este modelo, eso llevaría a un desperdicio de
recursos (dado que el modelo 67 tenía todo lo necesario para operar en
modo multitarea).

La respuesta de *ibm* fue muy ingeniosa: desarrollar un sistema
operativo mínimo, *cp* (/Control Program/, Programa de Control) con el
único propósito de crear y gestionar /máquinas virtuales/ en del
hardware S/360-67, dentro de /cada una de las cuales/ pudiera
ejecutarse /sin requerir modificaciones/ un sistema operativo estándar
de la serie 360. Entre los varios sistemas operativos disponibles para
la S/360, el que más frecuentemente se utilizó fue el /*cms*/,[fn::
Originalmente, las siglas *cms* eran por el /Cambridge Monitor
System/, por haber sido desarrollado en la división de investigación
de *ibm* en Cambridge, pero posteriormente fue renombrado a
/Conversational Monitor System/, /Sistema de Monitoreo
Conversacional/.] un sistema sencillo, interactivo y monousuario. La
combinación *cp/cms* proporcionaba un sistema operativo multiusuario,
con plena protección entre procesos, y con compatibilidad con los
modelos más modestos de la serie 360.

Aún después de la vida útil de la serie 360 original, *ibm* mantuvo
compatibilidad con este modelo hacia la serie 370, e incluso hoy, 50
años más tarde, se encuentra aún como
#+latex: z/\textbf{vm}
#+html: z/<b>vm</b>
/z/VM/ en la línea de /Sistemas z/.

Vale la pena mencionar que tanto *cp* como *cms* fueron distribuidos
desde el principio de forma consistente con lo que en la actualidad se
conoce como /software libre/: *ibm* los distribuía en fuentes, con
permiso de modificación y redistribución, y sus diferentes usuarios
fueron enviando las mejoras que realizaban de vuelta a *ibm*, de modo
que hoy incorpora el trabajo de 50 años de desarrolladores.

** El hipervisor

El modelo *cp/cms* lleva a una separación bastante limpia entre un
/multiplexador de hardware/ (*cp*) y el sistema operativo propiamente
dicho (*cms*). Y si bien la dupla puede ser vista como un sólo sistema
operativo, conforme se fueron ejecutando en máquinas virtuales
sistemas operativos más complejos se hizo claro que el *cp* tendría que
ser /otra cosa/. Partiendo del concepto de que el sistema operativo
es el /supervisor/ de la actividad de los usuarios, yendo un paso más
hacia arriba, se fue popularizando el nombre de /hipervisor/ para el
programa que administra y virtualiza a los supervisores. Algunas
características primarias que definen qué es un hipervisor son:

- Es únicamente un /micro-sistema operativo/, dado que no cubre muchas
  de las áreas clásicas ni presenta las interfaces abstractas al
  usuario final —sistemas de archivos, mecanismos de comunicación
  entre procesos, gestión de memoria virtual, evasión de bloqueos,
  etcétera.

- Se limita a gestionar bloques de memoria física contiguos y fijos,
  asignación de dispositivos y /poco/ más que eso.

- Normalmente no tiene una interfaz usuario directa, sino que es
  administrado por medio de llamadas privilegiadas desde alguno de los
  sistemas operativos huésped.

Estas líneas se han ido haciendo borrosas con el tiempo. Ahora,
por ejemplo, muchos hipervisores entienden a los sistemas de archivos,
permitiendo que los espacios de almacenamiento ofrecidos a sus
sistemas operativos huésped sean simples archivos para el sistema
anfitrión (y no particiones o dispositivos enteros). Algunos
hipervisores, como *kvm* bajo Linux se presentan integrados como un
componente más de un sistema operativo estándar.

** Virtualización asistida por hardware en x86

Hasta alrededor del año 2005, la virtualización no se mencionaba muy
frecuentemente. Si bien había hardware virtualizable 40 años atrás,
era bastante especializado— y caro. Ese año, Intel sacó al mercado los
procesadores con las extensiones necesarias para la virtualización,
bajo el nombre /Vanderpool Technology/ (o
#+latex: \textbf{vt}/x).
#+html: Free<b>vt</b>/x).
Al año siguiente, *amd* hizo lo propio, denominándolas /extensiones
Pacífica/. Ahora casi todas las computadoras de escritorio de rango
medio-alto tienen el sopote necesario para llevar a cabo
virtualización asistida por hardware. Y si bien en un principio el
tema tardó en tomar tracción, llevó a un replanteamiento completo de
la metodología de trabajo tanto de administradores de sistemas como de
programadores.

En contraste con las arquitecturas diseñadas desde un principio para
la virtualización, los usuarios de computadoras personales (inclusive
cuando éstas son servidores en centros de datos, siguen estando
basadadas en la misma arquitectura básica) se enfrentan a una mayor
variedad de dispositivos para todo tipo de tareas.[fn:: Una
descripción completa de la complejidad a la que debe enfrentarse un
hipervisor bajo arquitectura x86 excede con mucho el ámbito del
presente texto; se sugiere a los lectores interesados referirse al
excelente artículo que detallan la
implementación de /VMWare/ \parencite{Bugnion2012}.]  Si bien la
virtualización permite
aparentar varias computadoras distintas ejecutando sobre el mismo
procesador, ésta no incluye los dispositivos. Al presentarse una
máquina virtual, el sistema anfitrión esta casi siempre[fn:: Hay
mecanismos para reservar y dirigir un dispositivo físico existente a
una máquina virtual específica, pero hacerlo implica que este
dispositivo no será /multiplexado/ hacia las demás máquinas virtuales
que se ejecuten paralelamente.] emulando hardware. Claro está, lo más
frecuente es que el hipervisor ofrezca a los huéspedes la emulación de
dispositivos relativamente viejos y simples.[fn:: Por ejemplo, *kvm*
bajo Linux emula tarjetas de red tipo *ne2000*, tarjetas de sonido
tipo Soundblaster16 y tarjetas de video Cirrus Logic, todos ellos de
la década de los noventa.] Esto no significa que estén limitados a las
prestaciones del equipo emulado (por ejemplo, a los 10 Mbps para los
que estaba diseñada una tarjeta de red *ne2000*), sino que la interfaz
del núcleo para enviar datos a dicho dispositivo es una sencilla y que
ha sido empleada tanto tiempo que presenta muy poca inestabilidad.

Y este último punto permite un acercamiento mayor a una de las ventajas que
ofrecen los sistemas operativos virtualizados —la estabilidad. Los
controladores de dispositivos provistos por fabricante han sido
responsabilizados una y otra vez, y con justa razón, de la
inestabilidad de los sistemas operativos de escritorio. En particular,
son en buena medida culpables de la fama de inestabilidad que obtuvo
Windows. Los fabricantes de hardware no siempre gozan de suficiente
conocimiento acerca del sistema operativo como para escribir
controladores suficientemente seguros y de calidad, y por muchos años,
los sistemas Windows no implementaban mayor verificación al
comportamiento de los controladores — que, siendo un sistema
monolítico, eran código ejecutado con privilegios de núcleo.

Al emplear el sistema operativo huésped únicamente controladores
ampliamente probados y estabilizados a lo largo de muchos años, la
estabilidad que ofrece una máquina virtualizada muchas veces supera a
la que obtendría ejecutándose de forma nativa. Claro, el conjunto de
máquinas virtuales que se ejecute dentro de un sistema anfitrión
sigue siendo susceptible a cualquier inestabilidad del mismo sistema
anfitrión, sin embargo, es mucho menos probable que un programa mal
diseñado logre congelarse esperando respuesta del hardware (emulado),
y mucho menos afectar a los demás huéspedes.

* Paravirtualización
# <<VIRT_paravirt>>

La virtualización asistida por hardware, por conveniente que resulte,
sigue presentando algunas desventajas:

- No todos los procesadores cuentan con las extensiones de
  virtualización. Si bien cada vez es más común encontrarlas, es aún
  en líneas generales un factor de diferenciación entre las líneas
  económicas y de lujo.
- La capa de emulación, si bien es delgada, conlleva un cierto peso.
- Si bien es posible virtualizar arquitecturas como la x86, hay muchas
  otras para las cuales no se tienen las extensiones hardware
  necesarias.

La /paravirtualización/, o /virtualización asistida por el sistema
operativo/, parte de un planteamiento distinto: en vez de /engañar/ al
sistema operativo para que funcione sobre un sistema que parece real
pero no lo es, la paravirtualización busca hacerlo /con pleno
conocimiento y cooperación/ por parte de los sistemas huéspedes.  Esto
es, la paravirtualización consiste en alojar sistemas operativos
huésped que, a sabiendas de que están ejecutando en hardware
virtualizado, /no hacen llamadas directas a hardware/ sino que las
traducen a llamadas al sistema operativo anfitrión.

Vale la pena reiterar en este punto: los sistemas operativos huésped
bajo un entorno paravirtualizado saben que no están ejecutando sobre
hardware real, por lo que en vez de enviar las instrucciones que
controlen al hardware, envían llamadas al sistema a su
hipervisor. Hasta cierto punto, el proceso de adecuación
de un sistema para que permita ser paravirtualizado puede ser equivalente
a adecuar al sistema operativo para que ejecute en una arquitectura
nueva — muy parecida a la del hardware /real/, sí, pero con
diferencias fundamentales en aspectos profundos.

Y si bien ya se explicó en la sección anterior que la virtualización puede
ayudar a presentar un sistema idealizado que reduzca la inestabilidad
en un sistema operativo, al hablar de paravirtualización este
beneficio naturalmente crece: los controladores de hardware sencillos
y bien comprendidos que se usaban para gestionar los
dispositivos emulados se convierten casi en simples pasarelas de
llamadas al sistema, brindando además de una sobrecarga mínima, aun
mayor estabilidad por simplicidad del código.

** Paravirtualización y software libre

La paravirtualización resulta muy atractiva, presentando muy obvias
ventajas. Pero a pesar de que es posible emplearla en cualquier
arquitectura hardware, algunas veces no lo es.

Como se mencionó anteriormente, incorporar dentro de un sistema
operativo el soporte para una arquitectura de paravirtualización es
casi equivalente a traducirlo a una nueva arquitectura hardware. Para
que los autores de un entorno que implemente paravirtualización logren
que un sistema operativo nuevo pueda ser ejecutado en su arquitectura,
deben poder manipular y modificar su código fuente: de otra manera,
¿cómo se le podría adecuar para que supiera desenvolverse en un
entorno no nativo?

El proyecto de gestión de virtualización y paravirtualización /Xen/
nació como un proyecto académico de la Universidad de Cambridge,
presentando su versión 1.x mediante un artículo
\parencite{Barham2003}. Este artículo presenta su experiencia
paravirtualizando a una versión entonces actual de Linux y de
Windows. Sin embargo, Xen sólo pudo ser empleado por muchos años como
plataforma de paravirtualización de Linux porque, dado que la
adaptación de Windows se realizó bajo los términos del /Academic
Licensing Program/, que permitía a los investigadores acceso y
modificación al código fuente, pero no su redistribución —la versión
paravirtualizable de Windows *xp* fue desarrollada, pero no puede
distribuirse fuera de los participantes de dicho programa de
licenciamiento.

En tanto, el trabajo necesario para lograr la paravirtualización de
un sistema operativo libre, como Linux,
#+latex: Free\textbf{bsd}
#+html: Free<b>bsd</b>
u otros, puede ser
libremente redistribuido. No sólo eso, sino que el esfuerzo de
realizar la adaptación pudo compartirse entre desarrolladores de todo
el mundo, dado que esta entonces novedosa tecnología resultaba de gran
interes.

** Paravirtualización de dispositivos

Las ideas derivadas de la paravirtualización pueden emplearse también
bajo entornos basados en virtualización plena: si el sistema operativo
está estructurado de una forma modular (sin que esto necesariamente
signifique que es un sistema /microkernel/, sino que permita la carga
dinámica de controladores o /drivers/ para el hardware, como
prácticamente la totalidad de sistemas disponibles comercialmente hoy
en día), no hace falta modificar al sistema operativo completo para
gozar de los beneficios de la paravirtualización en algunas áreas.

De esta manera, si bien es posible ejecutar un sistema operativo /sin
modificaciones/ que espera ser ejecutado en hardware real, los
dispositivos que típicamente generan más actividad de entrada y
salida[fn:: Medios de almacenamiento, interfaz de red y salida de
video.] pueden ser atendidos por drivers paravirtuales. Por supuesto,
varios aspectos que son parte del núcleo /duro/ del sistema, como la
administración de memoria o el manejo de interrupciones (incluyendo el
temporizador) tendrán que seguirse manejando mediante una emulación,
aunque mucho más delgada.

Según mediciones empíricas realizadas en 2007 por Qumranet (quienes
liderearon el desarrollo del módulo de virtualización asistido por
hardware *kvm* en Linux), las clases de dispositivos =virtio= y =pv=
resultaron entre 5 y 10 veces más rápidas que la emulación de
dispositivos reales.

Mediante esta estrategia es posible ejecutar sistemas operativos
propietarios, como los de la familia Windows, con buena parte de las
ventajas de la paravirtualización, sobre entornos de virtualización
asistida por hardware.

* Contenedores
# <<VIRT_contenedores>>

Una estrategia completamente distinta para la creación de máquinas
virtuales es la de /contenedores/. A diferencia de emulación,
virtualización asistida por hardware y paravirtualización, al emplear
contenedores /sólo se ejecuta un sistema operativo/, que es el mismo
para los sistemas anfitrión y huésped. El anfitrión implementará una
serie de medidas para /aumentar el grado de separación/ que mantiene
entre procesos, agregando la noción de /contextos/ o /grupos/ que
se describirán en breve. Dado que el sistema operativo es el
único autorizado para tener acceso directo al hardware, no hace falta
ejecutar un hipervisor.

Podría presentarse un símil: las tecnologías antes descritas de
virtualización implementan /hardware virtual/ para cada sistema
operativo, mientras que los contenedores más bien presentan un
/sistema operativo virtual/ para el conjunto de procesos que definen
el comportamiento de cada máquina virtual —muchos autores presentan la
virtualización por contenedores bajo el nombre /virtualización a nivel
sistema operativo/. Y si bien el efecto a ojos del usuario puede ser
comparable, este método más que una multiplexación de máquinas
virtuales sobre hardware real opera mediante restricciones adicionales
sobre los procesos de usuario.

Al operar a un nivel más alto, un contenedor presenta algunas
limitantes adicionales (principalmente, se pierde la flexibilidad de
ejecutar sistemas operativos distintos), pero obtiene también
importantes ventajas.

El desarrollo histórico de los contenedores puede rastrearse a la
llamada al sistema =chroot()=, que restringe la visión del sistema de
archivos de un proceso a sólo el directorio hacia el cual ésta fue
invocada.[fn:: La llamada =chroot()= fue creada por Bill Joy en 1982
para ayudarse en el desarrollo del sistema Unix *4.2bsd*. Joy buscaba
probar los cambios que iba haciendo en los componentes en espacio de
usuario del sistema sin modificar su sistema /vivo/ y en producción,
esto es, sin tener que reinstalar y reiniciar cada vez, y con esta
llamada le fue posible instalar los cambios dentro de un directorio
específico y probarlos como si fueran en la raíz.] Esto es, si dentro
de un proceso se invoca =chroot('/usr/local')= y posteriormente se le
pide abrir el archivo =/boot.img=, a pesar de que éste indique una
ruta absoluta, el archivo que se abrirá será =/usr/local/boot.img=

Ahora bien, =chroot()= no es (ni busca ser) un verdadero aislamiento,
sólo proporciona un inicio[fn:: Como referencia a por qué no es un
verdadero aislamiento, puede referirse a \parencite{Simes2002}] —pero
conforme más usuarios comenzaban a utilizarlo para servicios en
producción, se hizo claro que resultaría útil ampliar la conveniencia
de =chroot()= a un verdadero aislamiento.

El primer sistema en incorporar esta funcionalidad fue
#+latex: Free\textbf{bsd}
#+html: Free<b>bsd</b>
creando el subsistema /Jails/ a partir de su versión 4.0, del
año 2000. No tardaron mucho en aparecer implementaciones comparables
en los distintos sistemas Unix. Hay incluso un producto propietario,
el /Parallels Virtuozzo Containers/, que implementa esta
funcionalidad para sistemas Windows.

Un punto importante a mencionar cuando se habla de contenedores es que
se pierde buena parte de la universalidad mencionada en las secciones
anteriores. Si bien las diferentes implementaciones comparten
principios básicos de operación, la manera en que logran la separación
e incluso la nomenclatura que emplean difieren fuertemente.

El núcleo del sistema crea un /grupo/ para cada /contenedor/ (también
conocido como /contexto de seguridad/), aislándolos entre sí por lo
menos en las siguientes áreas:

- Tablas de procesos :: Los procesos en un sistema Unix se presentan
     como un árbol, en cuya raíz está siempre el proceso 1,
     =init=. Cada contenedor inicia su existencia ejecutando un =init=
     propio y enmascarando su identificador de proceso real por el
     número 1.
- Señales, comunicación entre procesos :: Ningún proceso de un
     contenedor debe poder interferir con la ejecución de uno en otro
     contenedor. El núcleo restringe toda comunicación entre procesos,
     regiones de memoria compartida y envío de señales entre procesos
     de distintos grupos.
- Interfaces de red :: Varía según cada sistema operativo e
     implementación, pero en líneas generales, cada contenedor tendrá
     una interfaz de red con una /dirección de acceso a medio (*mac*)/
     distinta.[fn:: Es común referirse a las direcciones *mac* como
     direcciones físicas, sin embargo, todas las tarjetas de red
     permiten configurar su dirección, por lo cual la apelación
     /física/ resulta engañosa.] Claro está, cada una de ellas
     recibirá una diferente dirección *ip*, y el núcleo ruteará e
     incluso aplicará reglas de firewall entre ellas.
- Dispositivos de hardware :: Normalmente los sistemas huésped no
     tienen acceso directo a ningún dispositivo en hardware. En
     algunos casos, el acceso a dispositivos será multiplexado y, en
     otros, un dispositivo puede especificarse por medio de su
     configuración. Cabe mencionar que, dado que esta multiplexión no
     requiere /emulación/, sino únicamente una cuidadosa
     /planificación/, no resulta tan oneroso como la emulación.
- Límites en consumo de recursos :: Casi todas las implementaciones
     permiten asignar cotas máximas para el consumo de recursos
     compartidos, como espacio de memoria o disco o tiempo de *cpu*
     empleados por cada uno de los contenedores.
- Nombre del equipo :: Aunque parezca trivial, el nombre con el que
     una computadora /se designa a sí misma/ debe también ser
     aislado. Cada contenedor debe poder tener un nombre único e
     independiente.

Una de las principales características que atrae a muchos
administradores a elegir la virtualización por medio de contenedores
es un consumo de recursos óptimo: bajo los demás métodos de
virtualización (y, particularmente, al hablar de emulación y de
virtualización asistida por hardware), una máquina virtual siempre
ocupará algunos recursos, así esté inactiva. El hipervisor tendrá que
estar notificando a los temporizadores, enviando los paquetes de red
recibidos, etc. Bajo un esquema de contenedores, una máquina virtual
que no tiene trabajo se convierte sencillamente en un grupo de
procesos /dormidos/, probables candidatos a ser /paginados/ a disco.

* Ejercicios

** Preguntas de autoevaluación

1. En este capítulo se presentaron diversas tecnologías para la
   virtualización: emulación, virtualización asistida por hardware,
   paravirtualización y contenedores. Las cuatro categorías tienen su
   lugar y casos de uso recomendados. Elabore un cuadro comparativo,
   presentando las ventajas y desventajas relativas de cada categoría
   respecto a las demás.

2. A continuación se presentan varias afirmaciones. Evalúe si cada una
   de ellas es verdadera o falsa, sustentando con argumentos su
   conclusión.

   - La emulación implica naturalmente implementar un intérprete del
     código que fue originado para una arquitectura distinta. Este
     proceso necesariamente tiene un alto costo en tiempo de cómputo,
     y una infraestructura basada en emulación siempre será por lo
     menos un órden de magnitud más lenta que lo que resultaría de su
     ejecución nativa. La popularización de la emulación deriva, por
     un lado, de la diferencia de poder de cómputo entre las
     arquitecturas de escritorio y las embebidas y, por el otro, de la
     conveniencia de contar con código que pueda ser transportado
     fácilmente (/write once, run anywhere/).

   - La /Ley de Moore/ (presentada en la sección
     \ref{HW_multiprocesamiento}) ha llevado a una cada vez mayor
     integración y ha llevado a que el desarrollo del cómputo por fin
     cruzara obligadamente por el multiprocesamiento, el desarrollo de
     código paralelizable es mucho más complejo para los
     programadores; casi todo el material de la presente obra deriva
     del cuestionamiento de cómo compartir recursos entre procesos
     rivales.

     En este sentido, una de las grandes ventajas que ofrece la
     virtualización es que, al separar las aplicaciones en máquinas
     virtuales distintas, mantener una separación de recursos se
     simplifica. Cada máquina virtual puede correr en un entorno
     monotarea, con la ilusión de recursos dedicados.

3. De los recursos que administra un sistema operativo, algunos pueden
   ser fácilmente compartidos, en tanto que otros requieren un uso
   exclusivo para cada una de las máquinas virtuales. ¿Cuáles
   entrarían en cada una de estas clases, qué estrategia podría
   sugerir para compartir un dispositivo cuya naturaleza fuera de uso
   exclusivo?

4. Identifique cuál de las siguientes afirmaciones describe la mayor
   diferencia entre la paravirtualización y la virtualización asistida
   por hardware:

   1. La virtualización asistida por hardware requiere de electrónica
      específica para ser empleada, mientras que la paravirtualización
      evalúa por software todas las instrucciones e intercepta las
      instrucciones "peligrosas", a cambio de un menor rendimiento.

   2. La virtualización permite ejecutar al sistema huésped sin
      modificaciones, como si fuera en una computadora real, mientras
      que la paravirtualización requiere que éste esté preparado para
      ser virtualizado.

   3. Se efectúa únicamente sobre cada uno de los dispositivos,
      mientras que la virtualización plena se aplica sobre del sistema
      completo.

5. En el corazón de las arquitecturas de virtualización asistida por
   hardware encontraremos un programa llamado hipervisor. Indique
   cuáles de las siguientes afirmaciones respecto a esta tecnología
   son verdaderas, y cuáles falsas. Busque sustentarlo con ejemplos de
   sistemas existentes.

   1. Monitorea la actividad de los sistemas operativos.

   2. Se mantiene completamente invisible ante la perspectiva del
      sistema huésped.

   3. Es completamente transparente: un hipervisor debe poder correr
      otros dentro de sí.

   4. Cubre algunas de las tareas que realiza normalmente el sistema
      operativo.

# La siguiente pregunta me gusta, pero hay que agregar conceptos para
# que tenga un nivel apto de complejidad / interés.

# 4. Los contenedores son un enfoque muy distinto al de las otras
#    tecnologías de la virtualización y, sin embargo, logra un resultado
#    bastante similar. Los contenedores existen dentro de un mismo
#    sistema operativo, aprovechando algunas estructuras básicas.

#    Para los conceptos, /chroot/ y /contenedores o contextos de
#    seguridad/, elija de la siguiente lista cuál definición corresponde
#    a cada uno.

#    - Al ejecutarse todos los huéspedes sobre del mismo núcleo (sistema
#      operativo), éste tiene que efectuar una restricción de las
#      máquinas virtuales para que no interfieran entre sí. ¿Cómo se
#      denomina típicamente cada una de las máquinas virtuales desde el
#      punto de vista del sistema operativo?

#    - Llamada al sistema que restringe la vista que tiene un proceso
#      sobre del sistema de archivos, a partir de la cual se desarrolla
#      la idea de contenedores.



** Temas de investigación sugeridos

- Sistemas operativos mínimos para la nube ::

  Al hablar de virtualización, sea asistida por hardware o
  paravirtualización, varias voces se han levantado, indicando que
  ejecutar un sistema operativo completo dentro de una máquina virtual
  es un desperdicio de recursos. A fin de cuentas, si el sistema
  operativo típico a correr dentro de una máquina virtual en el *cp* del
  S/360 de *ibm*, hace más de 40 años, era un sistema /sencillo,
  interactivo y monousuario/ (*cms*), ¿por qué no repetir la
  experiencia?

  Un ejemplo de sistema mínimo fue presentado en septiembre de 2013:
  #+latex: \textbf{os}v.
  #+html: <b>os</b>v.
  Este sistema busca /no implementar/ los subsistemas innecesarios de
  un Linux tradicional, sino únicamente permitir la ejecución de
  varios de los procesos más comunes en una máquina virtual. Pueden
  buscar al respecto:

  - Presentación del proyecto, del congreso CloudOpen:
    \parencite{Laor2013}
  - Presentación técnica del proyecto, del congreso anual USENIX:
    \parencite{Kivity2014}
  - Artículo periodístico respecto al lanzamiento de OSv en The
    Register: \parencite{Clark2013}

  Algunos puntos a desarrollar:
  - Qué gana
    #+latex: \textbf{os}v
    #+html: <b>os</b>v
    y otros proyectos por el estilo, y qué pierden.
  - Cómo ha avanzado la adopción de estas ideas.
  - Qué le agrega o quita a la complejidad de la administración de
    sistemas.

** Lecturas relacionadas
- \fullcite{Bugnion2012}
- \fullcite{VMWare2006}
- \fullcite{Agesen2007}
- \fullcite{Barham2003}
- \fullcite{Kivity2007}
- \fullcite{Laor2007}
- \fullcite{Simes2002}
- \fullcite{CorbetNotesContainer}
- \fullcite{Menage2004}
